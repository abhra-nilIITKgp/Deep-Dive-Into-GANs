{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets,  transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pad1 = nn.ZeroPad2d(2)\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, bias = False)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, bias = False)\n",
    "        self.conv3 = nn.Conv2d(16, 120, 5, bias = False)\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pad1(x)\n",
    "        x = F.avg_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.avg_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(-1, 120)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim = 1)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "trainset = datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(trainloader):\n",
    "    inputs, labels = data\n",
    "    print(inputs.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1  2000] loss: 0.0001917\n",
      "[1  4000] loss: 0.0000634\n",
      "[1  6000] loss: 0.0001461\n",
      "[1  8000] loss: 0.0000000\n",
      "[1 10000] loss: 0.0000001\n",
      "[1 12000] loss: 0.0000003\n",
      "[1 14000] loss: 0.0000147\n",
      "[2  2000] loss: 0.0000000\n",
      "[2  4000] loss: 0.0000000\n",
      "[2  6000] loss: 0.0000002\n",
      "[2  8000] loss: 0.0000629\n",
      "[2 10000] loss: 0.0000006\n",
      "[2 12000] loss: 0.0000001\n",
      "[2 14000] loss: 0.0000003\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(2):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        \n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if(i%2000 ==1999):\n",
    "            print('[%d %5d] loss: %.7f' % (epoch+1, i+1, running_loss/2000))\n",
    "        running_loss = 0.0    \n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 0 : 98 %\n",
      "Accuracy of 1 : 98 %\n",
      "Accuracy of 2 : 96 %\n",
      "Accuracy of 3 : 96 %\n",
      "Accuracy of 4 : 94 %\n",
      "Accuracy of 5 : 95 %\n",
      "Accuracy of 6 : 97 %\n",
      "Accuracy of 7 : 97 %\n",
      "Accuracy of 8 : 95 %\n",
      "Accuracy of 9 : 94 %\n",
      "accuracy of test set is 96.57 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "class_correct = list( 0.0 for i in range(10))\n",
    "class_total = list(0.0 for i in range(10))\n",
    "correct = 0.0\n",
    "total = 0.0\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "  for data in testloader:\n",
    "    input, labels = data\n",
    "    output_raw = model(input)\n",
    "    output = torch.argmax(output_raw,1)\n",
    "    c = (output == labels)\n",
    "    \n",
    "    for i in range(4):\n",
    "      label = labels[i]\n",
    "      class_correct[label] += c[i].item()\n",
    "      class_total[label] += 1\n",
    "      correct += c[i].item()\n",
    "      total +=1\n",
    "      \n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %1d : %2d %%' % (\n",
    "        i, 100 * class_correct[i] / class_total[i]))\n",
    "    \n",
    "print ('accuracy of test set is %2.2f %%' % (correct/total*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "#     img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 0, 3, 4])\n",
      "tensor([[-2.3083e+02, -2.1052e+02, -2.0586e+02, -3.3400e+02, -1.8890e+02,\n",
      "         -2.1470e+02,  0.0000e+00, -3.4939e+02, -2.2448e+02, -3.1782e+02],\n",
      "        [ 0.0000e+00, -7.1155e+01, -3.0598e+01, -1.1237e+02, -4.0471e+01,\n",
      "         -9.2396e+01, -2.2262e+01, -4.4681e+01, -2.8259e+01, -3.0956e+01],\n",
      "        [-5.1855e+01, -2.8720e+01, -1.3549e+01, -3.8147e-05, -3.4353e+01,\n",
      "         -2.7036e+01, -5.6658e+01, -2.1905e+01, -1.0211e+01, -2.8754e+01],\n",
      "        [-4.6931e+01, -4.3650e+01, -2.4516e+01, -7.8368e+01,  0.0000e+00,\n",
      "         -5.5987e+01, -3.1546e+01, -3.7364e+01, -2.5911e+01, -2.3235e+01]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([6, 0, 3, 4])\n",
      "tensor([1, 1, 1, 1], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "input, labels = dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(input))\n",
    "print(labels)\n",
    "print\n",
    "output = model(input)\n",
    "print(output)\n",
    "\n",
    "out = torch.argmax(output, 1)\n",
    "print(out)\n",
    "\n",
    "print(out == labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
